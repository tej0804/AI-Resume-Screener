{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:31:48.636170100Z",
     "start_time": "2026-01-10T13:31:47.617034200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud"
   ],
   "id": "3918b5c07a7b6525",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-10T13:31:45.669428400Z",
     "start_time": "2026-01-10T13:31:45.549252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import os"
   ],
   "id": "804f7b3c6d8a70ff",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:31:51.577374300Z",
     "start_time": "2026-01-10T13:31:51.495589400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('resumes/UpdatedResumeDataSet.csv')\n",
    "df.head()"
   ],
   "id": "82f75eea4a6522a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Category                                             Resume\n",
       "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.shape",
   "id": "4581a8ba67ff6b05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.Category.value_counts()",
   "id": "5b7579f2e4cd1fd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.histplot(df['Category'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ],
   "id": "8c7677025e5d3244",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "counts=df['Category'].value_counts()\n",
    "labels=df['Category'].nunique()\n",
    "labels"
   ],
   "id": "6749e4168d8992e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['Category'].unique()",
   "id": "ccc786f94b128f60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "counts=df['Category'].value_counts()\n",
    "labels=df['Category'].unique()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.pie(counts,labels=labels,autopct='%1.1f%%',shadow=True,colors=plt.cm.plasma(np.linspace(0,1,3)))\n",
    "plt.show()"
   ],
   "id": "b15cccc217fffb7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['Resume'][0]",
   "id": "858e60f5635f128c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Skill extraction",
   "id": "1ba8a209e1bc5492"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:07.757342900Z",
     "start_time": "2026-01-10T13:32:07.376197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import string\n",
    "import re\n",
    "def clean_resume_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove urls\n",
    "    text = re.sub(r'http\\S+|www\\S+', ' ', text)\n",
    "\n",
    "    # remove emails\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)\n",
    "\n",
    "    # remove html tags\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "\n",
    "    # keep letters, numbers and spaces (IMPORTANT)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "\n",
    "    # normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df['cleaned_resume']=df['Resume'].apply(clean_resume_text)"
   ],
   "id": "69050f4d146eb7c9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['Resume'][0]",
   "id": "786f2a3b77ad4ca1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"\\nCLEANED RESUME:\\n\")\n",
    "print(df['cleaned_resume'][0][:600])\n"
   ],
   "id": "f2a3482727aea832",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:13.059217400Z",
     "start_time": "2026-01-10T13:32:13.018351800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SKILL_ALIASES = {\n",
    "    'naive bayes': ['naive bayes', 'na ve bayes'],\n",
    "    'scikit-learn': ['scikit learn', 'scikit-learn'],\n",
    "    'opencv': ['opencv', 'open cv'],\n",
    "    'natural language processing': ['nlp', 'natural language processing'],\n",
    "    'machine learning': ['machine learning', 'ml'],\n",
    "    'deep learning': ['deep learning', 'dl']\n",
    "}\n"
   ],
   "id": "bf13fcc30ebfc694",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:13.887480400Z",
     "start_time": "2026-01-10T13:32:13.865094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_skills_advanced(text, skill_aliases):\n",
    "    extracted = set()\n",
    "    for skill, variants in skill_aliases.items():\n",
    "        for variant in variants:\n",
    "            if variant in text:\n",
    "                extracted.add(skill)\n",
    "    return list(extracted)\n"
   ],
   "id": "4105190831a71d5f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:14.551445800Z",
     "start_time": "2026-01-10T13:32:14.504825200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['skills'] = df['cleaned_resume'].apply(\n",
    "    lambda x: extract_skills_advanced(x, SKILL_ALIASES)\n",
    ")\n"
   ],
   "id": "be3c7a4d91bdde54",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "3aff89dd46dbb17f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Education Extraction\n",
   "id": "37ae9805e609da33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:19.135150300Z",
     "start_time": "2026-01-10T13:32:19.088074300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EDUCATION_PATTERNS = {\n",
    "    \"doctorate\": [\n",
    "        r\"\\bph\\s*\\.?\\s*d\\b\",\n",
    "        r\"\\bdoctorate\\b\"\n",
    "    ],\n",
    "    \"postgraduate\": [\n",
    "        r\"\\bm\\s*\\.?\\s*tech\\b\",\n",
    "        r\"\\bm\\s*\\.?\\s*e\\b\",\n",
    "        r\"\\bm\\s*\\.?\\s*sc\\b\",\n",
    "        r\"\\bmaster\\b\",\n",
    "        r\"\\bmba\\b\"\n",
    "    ],\n",
    "    \"undergraduate\": [\n",
    "        r\"\\bb\\s*\\.?\\s*tech\\b\",\n",
    "        r\"\\bb\\s*\\.?\\s*e\\b\",\n",
    "        r\"\\bb\\s*\\.?\\s*sc\\b\",\n",
    "        r\"\\bbachelor\\b\",\n",
    "        r\"\\bdegree\\b\"\n",
    "    ]\n",
    "}\n"
   ],
   "id": "9f10022d49c16c1c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:21.191450300Z",
     "start_time": "2026-01-10T13:32:21.140685100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def extract_education(text, education_patterns):\n",
    "    found_levels = set()\n",
    "\n",
    "    for level, patterns in education_patterns.items():\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, text):\n",
    "                found_levels.add(level)\n",
    "\n",
    "    return list(found_levels)\n"
   ],
   "id": "6a2142fd76954dbf",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:22.531157800Z",
     "start_time": "2026-01-10T13:32:22.023468500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['education'] = df['cleaned_resume'].apply(\n",
    "    lambda x: extract_education(x, EDUCATION_PATTERNS)\n",
    ")\n"
   ],
   "id": "cf20dc069fe0fb41",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[['education']].head(10)\n",
   "id": "302850f7e16d7641",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:26.100245900Z",
     "start_time": "2026-01-10T13:32:26.051348400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EDU_RANK = {\n",
    "    \"undergraduate\": 1,\n",
    "    \"postgraduate\": 2,\n",
    "    \"doctorate\": 3\n",
    "}\n"
   ],
   "id": "a675fb810b6e0c12",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:26.658982400Z",
     "start_time": "2026-01-10T13:32:26.626371800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_highest_education(education_list):\n",
    "    if not education_list:\n",
    "        return 0\n",
    "    return max(EDU_RANK[e] for e in education_list)\n"
   ],
   "id": "6b4db2758f60c367",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:28.741897400Z",
     "start_time": "2026-01-10T13:32:28.705643400Z"
    }
   },
   "cell_type": "code",
   "source": "df['education_level'] = df['education'].apply(get_highest_education)\n",
   "id": "95c9c01f9f23b319",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['education_level'].head(10)",
   "id": "32e9100781d5f5d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experience extraction\n",
    "\n",
    "1. Layer A — Numeric duration extraction (regex)\n",
    "    Convert months → years\n",
    "    Normalize phrases like “less than 1 year”\n",
    "\n",
    "2. Layer B — Aggregate signal\n",
    "    If multiple durations appear → take max or sum (capped)\n",
    "\n",
    "3. Layer C — Bucket into levels\n",
    "    Junior\n",
    "    Mid\n",
    "    Senior"
   ],
   "id": "49617bdf102d3308"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:31.773926Z",
     "start_time": "2026-01-10T13:32:31.738404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EXPERIENCE_PATTERNS = {\n",
    "    \"months\": r\"(\\d+)\\s+months?\",\n",
    "    \"years\": r\"(\\d+)\\s*\\+?\\s*years?\",\n",
    "    \"less_than_year\": r\"less than\\s+1\\s+year\"\n",
    "}\n"
   ],
   "id": "101c0f6640fb76fa",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:32.350360700Z",
     "start_time": "2026-01-10T13:32:32.317990400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def extract_experience_years(text):\n",
    "    years = []\n",
    "\n",
    "    # match months\n",
    "    months = re.findall(EXPERIENCE_PATTERNS[\"months\"], text)\n",
    "    for m in months:\n",
    "        years.append(int(m) / 12)\n",
    "\n",
    "    # match years\n",
    "    yrs = re.findall(EXPERIENCE_PATTERNS[\"years\"], text)\n",
    "    for y in yrs:\n",
    "        years.append(int(y))\n",
    "\n",
    "    # handle \"less than 1 year\"\n",
    "    if re.search(EXPERIENCE_PATTERNS[\"less_than_year\"], text):\n",
    "        years.append(0.5)\n",
    "\n",
    "    if not years:\n",
    "        return 0.0\n",
    "\n",
    "    # cap total experience to avoid exaggeration\n",
    "    return min(sum(years), 10)\n"
   ],
   "id": "b233f75f56971f92",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:34.541036700Z",
     "start_time": "2026-01-10T13:32:34.452593900Z"
    }
   },
   "cell_type": "code",
   "source": "df['experience_years'] = df['cleaned_resume'].apply(extract_experience_years)\n",
   "id": "332366d1f4a3011d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:34.774040700Z",
     "start_time": "2026-01-10T13:32:34.734113300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def experience_bucket(years):\n",
    "    if years == 0:\n",
    "        return \"unknown\"\n",
    "    elif years < 2:\n",
    "        return \"junior\"\n",
    "    elif years < 5:\n",
    "        return \"mid\"\n",
    "    else:\n",
    "        return \"senior\"\n"
   ],
   "id": "9b5465b56d73359b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:36.069015700Z",
     "start_time": "2026-01-10T13:32:36.035986Z"
    }
   },
   "cell_type": "code",
   "source": "df['experience_level'] = df['experience_years'].apply(experience_bucket)\n",
   "id": "77a2f54c8e685949",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['experience_years'].head(10)",
   "id": "3544bbaa909bbb19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:39.382436Z",
     "start_time": "2026-01-10T13:32:39.289537400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "jd_path = \"resumes/job_descriptions.csv\"\n",
    "df_jd = pd.read_csv(jd_path)\n",
    "\n",
    "print(df_jd.shape)\n",
    "df_jd.head(2)\n"
   ],
   "id": "ecaf8170a7390c5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        job_title  company  location  \\\n",
       "0  Data Scientist   Dhurin       NaN   \n",
       "1  Data Scientist  GrowExx       NaN   \n",
       "\n",
       "                                     job_description  \n",
       "0  About the job About the Company Dhurin is a fa...  \n",
       "1  About the job About the Company Growexx is loo...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dhurin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About the job About the Company Dhurin is a fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GrowExx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About the job About the Company Growexx is loo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:44.006668600Z",
     "start_time": "2026-01-10T13:32:43.984463300Z"
    }
   },
   "cell_type": "code",
   "source": "df_jd[\"cleaned_jd\"] = df_jd[\"job_description\"].apply(clean_resume_text)\n",
   "id": "61721b1a985111ef",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:46.090038500Z",
     "start_time": "2026-01-10T13:32:46.049079800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#extract skills from JD\n",
    "df_jd[\"jd_skills\"] = df_jd[\"cleaned_jd\"].apply(\n",
    "    lambda x: extract_skills_advanced(x, SKILL_ALIASES)\n",
    ")\n"
   ],
   "id": "5775d08cc3ab862d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:47.590803500Z",
     "start_time": "2026-01-10T13:32:47.547170700Z"
    }
   },
   "cell_type": "code",
   "source": "df_jd[[\"job_title\", \"jd_skills\"]].head(5)\n",
   "id": "ee45f5f17af44983",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        job_title                                          jd_skills\n",
       "0  Data Scientist    [natural language processing, machine learning]\n",
       "1  Data Scientist    [natural language processing, machine learning]\n",
       "2  Data Scientist  [deep learning, scikit-learn, natural language...\n",
       "3  Data Scientist  [deep learning, natural language processing, m...\n",
       "4  Data Scientist  [deep learning, natural language processing, m..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>jd_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[natural language processing, machine learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[natural language processing, machine learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[deep learning, scikit-learn, natural language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[deep learning, natural language processing, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[deep learning, natural language processing, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:52.813763900Z",
     "start_time": "2026-01-10T13:32:52.792436900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# extracting experience requirements from JD\n",
    "df_jd[\"jd_experience_years\"] = df_jd[\"cleaned_jd\"].apply(extract_experience_years)\n",
    "df_jd[\"jd_experience_level\"] = df_jd[\"jd_experience_years\"].apply(experience_bucket)\n"
   ],
   "id": "6d3b4363d5fbf706",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_jd[[\"job_title\", \"jd_experience_level\"]].head()\n",
   "id": "260d12e2998dc82b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:32:57.262578900Z",
     "start_time": "2026-01-10T13:32:57.225200200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_jd[\"jd_education\"] = df_jd[\"cleaned_jd\"].apply(\n",
    "    lambda x: extract_education(x, EDUCATION_PATTERNS)\n",
    ")\n",
    "\n",
    "df_jd[\"jd_education_level\"] = df_jd[\"jd_education\"].apply(get_highest_education)\n"
   ],
   "id": "5dd4f322c689ff74",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_jd[[\"job_title\", \"jd_education_level\"]].head()\n",
   "id": "2fb5124c370c877",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Matching & ranking",
   "id": "862d66da76c72ada"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# skill overlap score\n",
    "def skill_match_score(resume_skills, jd_skills):\n",
    "    if not jd_skills:\n",
    "        return 0.0\n",
    "    overlap = set(resume_skills).intersection(set(jd_skills))\n",
    "    return len(overlap) / len(jd_skills)\n"
   ],
   "id": "718072e4339c9065",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# experience compatibility score\n",
    "EXPERIENCE_RANK = {\n",
    "    \"unknown\": 0,\n",
    "    \"junior\": 1,\n",
    "    \"mid\": 2,\n",
    "    \"senior\": 3\n",
    "}\n",
    "\n",
    "def experience_match_score(resume_level, jd_level):\n",
    "    if jd_level == \"unknown\":\n",
    "        return 0.5  # neutral\n",
    "    r = EXPERIENCE_RANK.get(resume_level, 0)\n",
    "    j = EXPERIENCE_RANK.get(jd_level, 0)\n",
    "\n",
    "    if r >= j:\n",
    "        return 1.0   # meets or exceeds requirement\n",
    "    elif r == j - 1:\n",
    "        return 0.5   # slightly underqualified\n",
    "    else:\n",
    "        return 0.0   # underqualified\n"
   ],
   "id": "8870295adbc69e72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#eductation compatibility score\n",
    "def education_match_score(resume_edu, jd_edu):\n",
    "    if jd_edu == 0:\n",
    "        return 0.5  # neutral\n",
    "    if resume_edu >= jd_edu:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n"
   ],
   "id": "adb3dd093848d73f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# FINAL WEIGHTED MATCH SCORE\n",
    "\n",
    "def final_match_score(resume_row, jd_row,\n",
    "                      w_skill=0.6, w_exp=0.3, w_edu=0.1):\n",
    "\n",
    "    skill_score = skill_match_score(\n",
    "        resume_row[\"skills\"], jd_row[\"jd_skills\"]\n",
    "    )\n",
    "\n",
    "    exp_score = experience_match_score(\n",
    "        resume_row[\"experience_level\"], jd_row[\"jd_experience_level\"]\n",
    "    )\n",
    "\n",
    "    edu_score = education_match_score(\n",
    "        resume_row[\"education_level\"], jd_row[\"jd_education_level\"]\n",
    "    )\n",
    "\n",
    "    final_score = (\n",
    "        w_skill * skill_score +\n",
    "        w_exp * exp_score +\n",
    "        w_edu * edu_score\n",
    "    )\n",
    "\n",
    "    return final_score\n"
   ],
   "id": "7c727ee19e3c2c2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "jd_idx = 0\n",
    "jd_row = df_jd.iloc[jd_idx]\n",
    "\n",
    "df[\"match_score\"] = df.apply(\n",
    "    lambda r: final_match_score(r, jd_row),\n",
    "    axis=1\n",
    ")\n"
   ],
   "id": "bf9c1ac5563cb8ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ranked_resumes = df.sort_values(\n",
    "    by=\"match_score\", ascending=False\n",
    ")\n",
    "\n",
    "ranked_resumes[\n",
    "    [\"Category\", \"skills\", \"experience_level\", \"education_level\", \"match_score\"]\n",
    "].head(10)\n"
   ],
   "id": "81a557129282101c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "obsrvations :\n",
    " 1. You are seeing a baseline saturation effect, which is expected\n",
    " 2. This is exactly why TF-IDF / embeddings / learned models come next\n",
    "\n",
    "final_score =\n",
    "  0.45 * rule_based_score +\n",
    "  0.55 * text_similarity\n"
   ],
   "id": "bcdba9a40464acfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TF-IDF text similarity",
   "id": "1e0ca839a1eae6e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ],
   "id": "15ae96ec1ddecef6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# building TF-IDF vectorizers\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=5000,\n",
    "    stop_words=\"english\"\n",
    ")\n"
   ],
   "id": "705e1d0eda6f3c55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# must fit on resume + JD together, hence use of combined corpus\n",
    "combined_corpus = (\n",
    "    df[\"cleaned_resume\"].tolist() +\n",
    "    df_jd[\"cleaned_jd\"].tolist()\n",
    ")\n",
    "\n",
    "tfidf.fit(combined_corpus)\n"
   ],
   "id": "f4018e3f8166314",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#transforming resumes and JDs to vectors\n",
    "resume_tfidf = tfidf.transform(df[\"cleaned_resume\"])\n",
    "jd_tfidf = tfidf.transform(df_jd[\"cleaned_jd\"])\n"
   ],
   "id": "c81550872f20611e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# compute TF_IDF similarity for one job\n",
    "jd_idx = 0\n",
    "jd_vector = jd_tfidf[jd_idx]\n",
    "\n",
    "tfidf_sim_scores = cosine_similarity(\n",
    "    resume_tfidf,\n",
    "    jd_vector\n",
    ").flatten()\n",
    "\n",
    "print(jd_vector)"
   ],
   "id": "fb6a8b1280c887dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"TF-IDF similarity stats:\")\n",
    "print(\"Min:\", tfidf_sim_scores.min())\n",
    "print(\"Max:\", tfidf_sim_scores.max())\n",
    "print(\"Mean:\", tfidf_sim_scores.mean())\n"
   ],
   "id": "f435ba75948c5fde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[\"tfidf_similarity\"] = tfidf_sim_scores\n",
   "id": "d114b8cd35352fc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[[\"tfidf_similarity\"]].describe()\n",
   "id": "6c7efcd05a2f49a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"rule_score\"] = df[\"match_score\"]\n",
    "\n"
   ],
   "id": "cd90185f90a42f2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"final_score_tfidf\"] = (\n",
    "    0.45 * df[\"rule_score\"] +\n",
    "    0.55 * df[\"tfidf_similarity\"]\n",
    ")\n"
   ],
   "id": "cf3e0ef6e34ea2b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ranked_resumes = df.sort_values(\n",
    "    by=\"final_score_tfidf\",\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "ranked_resumes[\n",
    "    [\"Category\", \"experience_level\", \"rule_score\", \"tfidf_similarity\", \"final_score_tfidf\"]\n",
    "].head(10)\n"
   ],
   "id": "99d34cbaa08b6d3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "code",
   "source": "%%sql\n",
   "id": "9197ff4993b5768c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "observations :\n",
    "1. Ordering changed → TF-IDF is influencing ranking\n",
    "\n",
    "2. TF-IDF values differ → signal exists\n",
    "\n",
    "3. Differences are small → expected for long documents\n",
    "\n",
    "\n",
    "TF-IDF improved ranking slightly, but due to lexical mismatch and long document length, semantic embeddings were needed for better discrimination"
   ],
   "id": "a3e96db1df976676"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TF-IDF provided limited resolution due to lexical mismatch in long unstructured documents, which motivated the use of Sentence-BERT for semantic similarity",
   "id": "40818d72c6881619"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SBBERT",
   "id": "8303012d8b7c3caa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:33:42.355402600Z",
     "start_time": "2026-01-10T13:33:40.306383800Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install sentence-transformers\n",
   "id": "ebfef4258614fcaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2026.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2026.1.4)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\tulsiram\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:33:52.223364900Z",
     "start_time": "2026-01-10T13:33:45.094269200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n"
   ],
   "id": "8cad30162d3d8cb1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TULSIRAM\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:33:55.879061800Z",
     "start_time": "2026-01-10T13:33:52.223742700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Loading SBERT model...\")\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"Model loaded\")\n"
   ],
   "id": "6d08b191ec35700",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SBERT model...\n",
      "Model loaded\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:33:55.909994200Z",
     "start_time": "2026-01-10T13:33:55.894891900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resume_texts = df[\"cleaned_resume\"].tolist()\n",
    "jd_texts = df_jd[\"cleaned_jd\"].tolist()\n"
   ],
   "id": "53e6df3db050243f",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:39:27.838961200Z",
     "start_time": "2026-01-10T13:39:27.738045400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Encoding test batch...\")\n",
    "\n",
    "test_embeddings = sbert_model.encode(\n",
    "    resume_texts[:5],\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "print(\"Test embeddings shape:\", test_embeddings.shape)\n"
   ],
   "id": "b90f06025779f655",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test batch...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sbert_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mEncoding test batch...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m test_embeddings = \u001B[43msbert_model\u001B[49m.encode(\n\u001B[32m      4\u001B[39m     resume_texts[:\u001B[32m5\u001B[39m],\n\u001B[32m      5\u001B[39m     convert_to_numpy=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m      6\u001B[39m )\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTest embeddings shape:\u001B[39m\u001B[33m\"\u001B[39m, test_embeddings.shape)\n",
      "\u001B[31mNameError\u001B[39m: name 'sbert_model' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:34:36.988656800Z",
     "start_time": "2026-01-10T13:33:58.687900400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resume_embeddings = sbert_model.encode(\n",
    "    resume_texts,\n",
    "    batch_size=16,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "jd_embeddings = sbert_model.encode(\n",
    "    jd_texts,\n",
    "    batch_size=16,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ")\n"
   ],
   "id": "16a5e07eddd6e029",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 61/61 [00:36<00:00,  1.68it/s]\n",
      "Batches: 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:39:18.401251400Z",
     "start_time": "2026-01-10T13:39:18.277920400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(resume_embeddings.shape)\n",
    "print(jd_embeddings.shape)\n"
   ],
   "id": "f933bed6b7a70e8b",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resume_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mresume_embeddings\u001B[49m.shape)\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(jd_embeddings.shape)\n",
      "\u001B[31mNameError\u001B[39m: name 'resume_embeddings' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:39:20.530399600Z",
     "start_time": "2026-01-10T13:39:20.441116700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Computing similarity test...\")\n",
    "test_sim = np.dot(\n",
    "    resume_embeddings[0],\n",
    "    jd_embeddings[0]\n",
    ") / (\n",
    "    np.linalg.norm(resume_embeddings[0]) *\n",
    "    np.linalg.norm(jd_embeddings[0])\n",
    ")\n",
    "\n",
    "print(\"Test similarity:\", test_sim)\n"
   ],
   "id": "d7de02d9b7e2554a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarity test...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mComputing similarity test...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m test_sim = \u001B[43mnp\u001B[49m.dot(\n\u001B[32m      3\u001B[39m     resume_embeddings[\u001B[32m0\u001B[39m],\n\u001B[32m      4\u001B[39m     jd_embeddings[\u001B[32m0\u001B[39m]\n\u001B[32m      5\u001B[39m ) / (\n\u001B[32m      6\u001B[39m     np.linalg.norm(resume_embeddings[\u001B[32m0\u001B[39m]) *\n\u001B[32m      7\u001B[39m     np.linalg.norm(jd_embeddings[\u001B[32m0\u001B[39m])\n\u001B[32m      8\u001B[39m )\n\u001B[32m     10\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTest similarity:\u001B[39m\u001B[33m\"\u001B[39m, test_sim)\n",
      "\u001B[31mNameError\u001B[39m: name 'np' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:35:56.002640400Z",
     "start_time": "2026-01-10T13:35:55.935554900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#compute SBERT similarity for ONE job\n",
    "\n",
    "jd_idx = 0\n",
    "jd_embedding = jd_embeddings[jd_idx]\n",
    "\n",
    "# cosine similarity manually (fast & clear)\n",
    "sbert_sim_scores = np.dot(\n",
    "    resume_embeddings,\n",
    "    jd_embedding\n",
    ") / (\n",
    "    np.linalg.norm(resume_embeddings, axis=1) *\n",
    "    np.linalg.norm(jd_embedding)\n",
    ")\n"
   ],
   "id": "1e28d61c3c17eaf7",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jd_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m#compute SBERT similarity for ONE job\u001B[39;00m\n\u001B[32m      3\u001B[39m jd_idx = \u001B[32m0\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m jd_embedding = \u001B[43mjd_embeddings\u001B[49m[jd_idx]\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# cosine similarity manually (fast & clear)\u001B[39;00m\n\u001B[32m      7\u001B[39m sbert_sim_scores = np.dot(\n\u001B[32m      8\u001B[39m     resume_embeddings,\n\u001B[32m      9\u001B[39m     jd_embedding\n\u001B[32m   (...)\u001B[39m\u001B[32m     12\u001B[39m     np.linalg.norm(jd_embedding)\n\u001B[32m     13\u001B[39m )\n",
      "\u001B[31mNameError\u001B[39m: name 'jd_embeddings' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:35:43.606139400Z",
     "start_time": "2026-01-10T13:35:43.032547400Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"sbert_similarity\"] = sbert_sim_scores\n",
   "id": "bbb1024c16ba64ff",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sbert_sim_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m df[\u001B[33m\"\u001B[39m\u001B[33msbert_similarity\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43msbert_sim_scores\u001B[49m\n",
      "\u001B[31mNameError\u001B[39m: name 'sbert_sim_scores' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:34:50.074388400Z",
     "start_time": "2026-01-10T13:34:49.312010500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"SBERT similarity stats:\")\n",
    "print(\"Min:\", df[\"sbert_similarity\"].min())\n",
    "print(\"Max:\", df[\"sbert_similarity\"].max())\n",
    "print(\"Mean:\", df[\"sbert_similarity\"].mean())\n"
   ],
   "id": "3f85462c9a76494b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT similarity stats:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sbert_similarity'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3811\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'sbert_similarity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mSBERT similarity stats:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mMin:\u001B[39m\u001B[33m\"\u001B[39m, \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msbert_similarity\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m.min())\n\u001B[32m      3\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mMax:\u001B[39m\u001B[33m\"\u001B[39m, df[\u001B[33m\"\u001B[39m\u001B[33msbert_similarity\u001B[39m\u001B[33m\"\u001B[39m].max())\n\u001B[32m      4\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mMean:\u001B[39m\u001B[33m\"\u001B[39m, df[\u001B[33m\"\u001B[39m\u001B[33msbert_similarity\u001B[39m\u001B[33m\"\u001B[39m].mean())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4112\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4113\u001B[39m indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4114\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4115\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3814\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3815\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3816\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3817\u001B[39m     ):\n\u001B[32m   3818\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3819\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3820\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3821\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3822\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3823\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3824\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'sbert_similarity'"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T13:36:49.041144500Z",
     "start_time": "2026-01-10T13:36:48.977631300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Why this weighting:\n",
    "# SBERT dominates (semantic understanding)\n",
    "# Rules enforce hard constraints\n",
    "# TF-IDF adds lexical precision\n",
    "\n",
    "\n",
    "df[\"final_score_sbert\"] = (\n",
    "    0.30 * df[\"rule_score\"] +\n",
    "    0.20 * df[\"tfidf_similarity\"] +\n",
    "    0.50 * df[\"sbert_similarity\"]\n",
    ")\n",
    "\n"
   ],
   "id": "58222bb0d5ba2fec",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m df[\u001B[33m\"\u001B[39m\u001B[33mfinal_score_sbert\u001B[39m\u001B[33m\"\u001B[39m] = (\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     \u001B[32m0.30\u001B[39m * \u001B[43mdf\u001B[49m[\u001B[33m\"\u001B[39m\u001B[33mrule_score\u001B[39m\u001B[33m\"\u001B[39m] +\n\u001B[32m      3\u001B[39m     \u001B[32m0.20\u001B[39m * df[\u001B[33m\"\u001B[39m\u001B[33mtfidf_similarity\u001B[39m\u001B[33m\"\u001B[39m] +\n\u001B[32m      4\u001B[39m     \u001B[32m0.50\u001B[39m * df[\u001B[33m\"\u001B[39m\u001B[33msbert_similarity\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m      5\u001B[39m )\n",
      "\u001B[31mNameError\u001B[39m: name 'df' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#rank resume using SBERT- enhanced scores\n",
    "ranked_resumes = df.sort_values(\n",
    "    by=\"final_score_sbert\",\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "ranked_resumes[\n",
    "    [\"Category\", \"rule_score\", \"tfidf_similarity\", \"sbert_similarity\", \"final_score_sbert\"]\n",
    "].head(10)\n"
   ],
   "id": "b9969631a31cca3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#comparing TF_IDF vs SBERT\n",
    "rank_compare = df.sort_values(\n",
    "    by=\"final_score_sbert\",\n",
    "    ascending=False\n",
    ")[\n",
    "    [\"rule_score\", \"tfidf_similarity\", \"sbert_similarity\"]\n",
    "].head(10)\n",
    "\n",
    "rank_compare\n"
   ],
   "id": "5cf9ee5e98e9972"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
